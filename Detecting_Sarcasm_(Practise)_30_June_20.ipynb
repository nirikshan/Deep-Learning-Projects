{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecting Sarcasm (Practise) 30 June 20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKIjCBcElapEOD6CA7ajCA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taniyasinghsisodia/Deep-Learning-Projects/blob/master/Detecting_Sarcasm_(Practise)_30_June_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4zjLSCDcyf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "b44a5f73-3cca-4f4b-e509-80a03decd39d"
      },
      "source": [
        "!wget --header 'Host: storage.googleapis.com' --user-agent 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://www.kaggle.com/' --header 'DNT: 1' --header 'Upgrade-Insecure-Requests: 1' 'https://storage.googleapis.com/kaggle-data-sets/30764%2F533474%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1593766907&Signature=fRABht2ntjN%2Bgn3Rpx%2BZ9%2FHRNlAb3M2jKn8DFWO7%2BiRYlJi0OzMPBhrx3TXfXvsnUel351MqOAAU8KVfV7VxpgKjY%2FW9LbnTcNX9n1TRUCYCUj91ET0CKVfl3G683uG%2FBQIPdHAzPg%2Fo%2B8odn3z2OtAWX8JbsFv3rwtAXJhf32wezhmsBCTV9YKL6CtQvGl9mUU58Jn5Y5iPTDJUAfcaKmv8zaMCzHPPxcWvzqYz9tZwS2jgDxkpBznjWGF4Z%2FXkt6XIm4I6RhOoNao5lR7LXarFWkN%2Bkzex17SeCuKnnY7SFc56VPnQlF8kLXzbiuQz6Xblly8VerjVGPUoo%2Fy8Og%3D%3D' --output-document '30764%2F533474%2Fbundle%2Farchive.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-30 09:06:01--  https://storage.googleapis.com/kaggle-data-sets/30764%2F533474%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1593766907&Signature=fRABht2ntjN%2Bgn3Rpx%2BZ9%2FHRNlAb3M2jKn8DFWO7%2BiRYlJi0OzMPBhrx3TXfXvsnUel351MqOAAU8KVfV7VxpgKjY%2FW9LbnTcNX9n1TRUCYCUj91ET0CKVfl3G683uG%2FBQIPdHAzPg%2Fo%2B8odn3z2OtAWX8JbsFv3rwtAXJhf32wezhmsBCTV9YKL6CtQvGl9mUU58Jn5Y5iPTDJUAfcaKmv8zaMCzHPPxcWvzqYz9tZwS2jgDxkpBznjWGF4Z%2FXkt6XIm4I6RhOoNao5lR7LXarFWkN%2Bkzex17SeCuKnnY7SFc56VPnQlF8kLXzbiuQz6Xblly8VerjVGPUoo%2Fy8Og%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 64.233.189.128, 108.177.125.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3460534 (3.3M) [application/zip]\n",
            "Saving to: ‘30764%2F533474%2Fbundle%2Farchive.zip’\n",
            "\n",
            "\r          30764%2F5   0%[                    ]       0  --.-KB/s               \r30764%2F533474%2Fbu 100%[===================>]   3.30M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-06-30 09:06:02 (117 MB/s) - ‘30764%2F533474%2Fbundle%2Farchive.zip’ saved [3460534/3460534]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqfiRetIdrnA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "16fccbdb-6ac1-4cc8-ddb6-f8b69366283c"
      },
      "source": [
        "!unzip 30764%2F533474%2Fbundle%2Farchive.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  30764%2F533474%2Fbundle%2Farchive.zip\n",
            "  inflating: Sarcasm_Headlines_Dataset.json  \n",
            "  inflating: Sarcasm_Headlines_Dataset_v2.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUVuSiGSepoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "2dc8d62f-e94d-4378-b7b0-e14793874327"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "data = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\",lines=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bQq-KA6fB9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c6e859ed-5073-4631-d3b9-4a101dd2ebd0"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clock of hair loss</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling short on gender, racial equality</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edwards-inequality_us_57455f7fe4b055bb1170b207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-veggies-9-delici_b_8899742.html</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting to work</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-prevents-liar-from-getting-to-work-1819576031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'streaming' correctly</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-close-to-using-word-streaming-cor-1819575546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                                                                 article_link\n",
              "0  1             ...  https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205\n",
              "1  0             ...  https://www.huffingtonpost.com/entry/donna-edwards-inequality_us_57455f7fe4b055bb1170b207  \n",
              "2  0             ...  https://www.huffingtonpost.com/entry/eat-your-veggies-9-delici_b_8899742.html              \n",
              "3  1             ...  https://local.theonion.com/inclement-weather-prevents-liar-from-getting-to-work-1819576031 \n",
              "4  1             ...  https://www.theonion.com/mother-comes-pretty-close-to-using-word-streaming-cor-1819575546  \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihPf7q0TfF1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "019eb697-eb9f-43bd-eb2e-b831b6ac52ab"
      },
      "source": [
        "data[\"is_sarcastic\"].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14985\n",
              "1    13634\n",
              "Name: is_sarcastic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH8Wzbm-fYCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "b09b2952-1142-4897-961b-581bd40f6655"
      },
      "source": [
        "sentences = data[\"headline\"].values\n",
        "sentences[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['thirtysomething scientists unveil doomsday clock of hair loss',\n",
              "       'dem rep. totally nails why congress is falling short on gender, racial equality',\n",
              "       'eat your veggies: 9 deliciously different recipes',\n",
              "       'inclement weather prevents liar from getting to work',\n",
              "       \"mother comes pretty close to using word 'streaming' correctly\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WS8ESZQfSZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1750a501-b9ae-4743-a352-177341df1030"
      },
      "source": [
        "labels = data[\"is_sarcastic\"].values\n",
        "labels[:5]\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecMB7crgQ0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "e27cbd16-f7d8-443c-863c-e979d02e2de4"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-30 10:23:21--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-06-30 10:23:21--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-06-30 10:23:22--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.22MB/s    in 6m 29s  \n",
            "\n",
            "2020-06-30 10:29:51 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVEYzxRPgq39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "988b2e42-b7ab-4ce6-c8b9-5b1f52e74d3c"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbscWGi9krSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKV8oSm_oYtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 50000\n",
        "MAX_SEQUENCE_LENGTH = 25\n",
        "EMBEDDING_DIM = 300\n",
        "VALIDATION_SPLIT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iprp5VRMnjV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(MAX_VOCAB_SIZE)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxmcQhkupXsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "63bc267e-df86-4f09-e730-7df7c236ebfe"
      },
      "source": [
        "# convert the sentences (strings) into integers\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "\n",
        "\n",
        "# get word -> integer mapping\n",
        "word2idx = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word2idx))\n",
        "\n",
        "\n",
        "# pad sequences so that we get a N x T matrix\n",
        "data_new = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', data.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 30884 unique tokens.\n",
            "Shape of data tensor: (28619, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WE0WL5PqGcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "f08ba851-b0e6-4441-8f8b-5f6267cb7030"
      },
      "source": [
        "data_new"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,     2,   660,  1118],\n",
              "       [    0,     0,     0, ...,  1527,  2153,  1844],\n",
              "       [    0,     0,     0, ..., 16004,   646,  1483],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,     6,   842,  1923],\n",
              "       [    0,     0,     0, ...,  2359,   837,  6295],\n",
              "       [    0,     0,     0, ...,     6,   259,   177]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlo4PqwBqhQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a9fc93cb-65f5-446e-8ba2-74348ef53dd7"
      },
      "source": [
        "# load in pre-trained word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open(\"glove.6B.300d.txt\") as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g2LMcNir0Nj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82304dde-2a4e-4df5-c2d7-648ac49ed005"
      },
      "source": [
        "# prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx.items():\n",
        "  if i < MAX_VOCAB_SIZE:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9pYI6d1zb3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c46f996-3ceb-48cd-af46-6a213bf1078d"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30885, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyEjLHZ71HKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5e83267-cc85-4bc1-dbf5-2706dfab8594"
      },
      "source": [
        "num_words"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFG6KVPfzgWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "a3ceea41-e1db-48da-b709-da184860e820"
      },
      "source": [
        "# load pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=MAX_SEQUENCE_LENGTH,\n",
        "  trainable=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "print('Building model...')\n",
        "\n",
        "# create an LSTM network with a single LSTM\n",
        "input_ = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "x = embedding_layer(input_)\n",
        "# x = LSTM(15, return_sequences=True)(x)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(15, return_sequences=True))(x)\n",
        "x = tf.keras.layers.GlobalMaxPool1D()(x)\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = tf.keras.models.Model(input_, output)\n",
        "model.compile(\n",
        "  loss='binary_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "print('Training model...')\n",
        "r = model.fit(\n",
        "  data_new,\n",
        "  labels,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=VALIDATION_SPLIT\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model...\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "179/179 [==============================] - 4s 22ms/step - loss: 0.4196 - accuracy: 0.8081 - val_loss: 0.3264 - val_accuracy: 0.8576\n",
            "Epoch 2/5\n",
            "179/179 [==============================] - 3s 17ms/step - loss: 0.2853 - accuracy: 0.8797 - val_loss: 0.3283 - val_accuracy: 0.8562\n",
            "Epoch 3/5\n",
            "179/179 [==============================] - 3s 17ms/step - loss: 0.2156 - accuracy: 0.9158 - val_loss: 0.3183 - val_accuracy: 0.8623\n",
            "Epoch 4/5\n",
            "179/179 [==============================] - 3s 17ms/step - loss: 0.1661 - accuracy: 0.9363 - val_loss: 0.3349 - val_accuracy: 0.8578\n",
            "Epoch 5/5\n",
            "179/179 [==============================] - 3s 17ms/step - loss: 0.1307 - accuracy: 0.9523 - val_loss: 0.3486 - val_accuracy: 0.8625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuuf_PV71jPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}